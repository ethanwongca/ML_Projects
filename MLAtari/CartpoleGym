{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CartPole Gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "\n",
    "import numpy as np\n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "action_space = env.action_space.n\n",
    "print(action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStateSize():\n",
    "    state=env.reset()\n",
    "    action = env.action_space.sample()\n",
    "    obs, _, _, _ = env.step(action)\n",
    "    return len(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "state_space = getStateSize()\n",
    "print(state_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random games test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def some_random_games_first():\n",
    "    for episode in range(5):\n",
    "        env.reset()\n",
    "        for t in range(500):\n",
    "            env.render()\n",
    "            action = env.action_space.sample()\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            if done:\n",
    "                env.close()\n",
    "                break\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(action_space, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating data and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_data(number_of_games, game_turns, acceptable_score):\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    one_hot = [0 for i in range(action_space)]\n",
    "\n",
    "    for i in range(number_of_games):\n",
    "        env.reset()\n",
    "        game_memory = []\n",
    "        prev_obs = []\n",
    "        score = 0\n",
    "\n",
    "        for turn in range(game_turns):\n",
    "\n",
    "            action = env.action_space.sample()\n",
    "            new_obs, reward, done, info = env.step(action)\n",
    "            # summing the final score\n",
    "            score += int(reward)\n",
    "\n",
    "            if turn > 0:\n",
    "                game_memory.append([prev_obs, int(action)])\n",
    "\n",
    "            prev_obs = new_obs\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "                \n",
    "        if score >= acceptable_score:\n",
    "            for data in game_memory:\n",
    "                X.append(np.array(data[0]).reshape(1, len(data[0])))\n",
    "                predicted_action = list(one_hot)\n",
    "                predicted_action[data[1]] = 1\n",
    "                y.append(np.array(predicted_action).reshape(1, action_space))\n",
    "    print('{} examples were made.'.format(len(X)))\n",
    "    return np.array(X).reshape(-1, 1, len(data[0])), np.array(y).reshape(-1, 1, action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2986 examples were made.\n"
     ]
    }
   ],
   "source": [
    "X, y = initial_data(3000, 200, 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 2388 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      " - 0s - loss: 0.6736 - acc: 0.5942 - val_loss: 0.6679 - val_acc: 0.6154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13a6c44a8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X, y=y, epochs=1, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(n_games, model=None):\n",
    "    for i in range(n_games):\n",
    "        env.reset()\n",
    "        prev_obs = []\n",
    "        score = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "            env.render()\n",
    "            if (model == None) or (len(prev_obs) < 1):\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                # otherwise we use our model to choose an\n",
    "                # action based on the current observation (state)\n",
    "                action = np.argmax(model.predict(prev_obs.reshape(-1, 1, state_space)))\n",
    "            new_obs, reward, done, _ = env.step(action)\n",
    "            prev_obs = new_obs\n",
    "            score += reward\n",
    "                \n",
    "        env.close()\n",
    "        print('Final score: {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score: 200.0\n",
      "Final score: 200.0\n",
      "Final score: 200.0\n",
      "Final score: 200.0\n",
      "Final score: 200.0\n",
      "Final score: 200.0\n",
      "Final score: 200.0\n",
      "Final score: 200.0\n",
      "Final score: 200.0\n",
      "Final score: 200.0\n"
     ]
    }
   ],
   "source": [
    "play_game(10, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
